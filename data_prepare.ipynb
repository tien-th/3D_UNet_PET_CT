{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "root_path = '/workdir/radish/PET-CT/3D_reggan/train/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_LENGTH = 3\n",
    "STEP = 2\n",
    "def save(save_dir, root_path, max_records = 6000): \n",
    "    input_dir = save_dir + '/A'\n",
    "    output_dir = save_dir + '/B'\n",
    "    os.makedirs(input_dir, exist_ok=True)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    index = 0 \n",
    "    num_patients = 0\n",
    "    for folder in os.listdir(root_path):\n",
    "        a = np.load(root_path + folder + '/predicted_volume.npy', allow_pickle=True)\n",
    "        b = np.load(root_path + folder + '/pet.npy', allow_pickle=True)\n",
    "        if (a.shape != b.shape):\n",
    "            print(folder)\n",
    "            print(a.shape)\n",
    "            print(b.shape)\n",
    "            print('----------------------')\n",
    "            continue\n",
    "        num_patients = num_patients + 1\n",
    "        for i in tqdm(range(0, a.shape[0]- CHUNK_LENGTH, STEP)):\n",
    "            inp = a[i:i+CHUNK_LENGTH]\n",
    "            out = b[i:i+CHUNK_LENGTH] \n",
    "            np.save(f'{input_dir}/{index}.npy', inp)\n",
    "            np.save(f'{output_dir}/{index}.npy', out)\n",
    "            index = index + 1 \n",
    "            if (index >= max_records):\n",
    "                return (index, num_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:00<00:00, 1193.40it/s]\n",
      "100%|██████████| 155/155 [00:00<00:00, 1584.27it/s]\n",
      "100%|██████████| 155/155 [00:00<00:00, 1594.55it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1524.85it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1448.65it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1555.98it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1533.03it/s]\n",
      "100%|██████████| 142/142 [00:00<00:00, 1615.83it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1663.53it/s]\n",
      "100%|██████████| 155/155 [00:00<00:00, 1586.32it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1540.49it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1359.54it/s]\n",
      "100%|██████████| 117/117 [00:00<00:00, 1540.71it/s]\n",
      "100%|██████████| 142/142 [00:00<00:00, 449.77it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1603.94it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1561.71it/s]\n",
      "100%|██████████| 155/155 [00:00<00:00, 1592.48it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1656.74it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1270.42it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1510.57it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 1544.92it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1529.32it/s]\n",
      "100%|██████████| 122/122 [00:00<00:00, 1539.69it/s]\n",
      "100%|██████████| 155/155 [00:00<00:00, 1409.62it/s]\n",
      "100%|██████████| 155/155 [00:00<00:00, 1585.17it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1517.33it/s]\n",
      "100%|██████████| 41/41 [00:00<00:00, 1371.31it/s]\n",
      "100%|██████████| 98/98 [00:00<00:00, 1518.09it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1558.56it/s]\n",
      "100%|██████████| 155/155 [00:00<00:00, 1617.61it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1605.06it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1546.71it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1628.00it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1591.27it/s]\n",
      "100%|██████████| 130/130 [00:00<00:00, 1547.81it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1548.71it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1518.61it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1522.87it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1520.95it/s]\n",
      "100%|██████████| 130/130 [00:00<00:00, 1624.65it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1525.19it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1665.88it/s]\n",
      "100%|██████████| 130/130 [00:00<00:00, 1620.66it/s]\n",
      "100%|██████████| 117/117 [00:00<00:00, 1537.97it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1642.51it/s]\n",
      "100%|██████████| 142/142 [00:00<00:00, 1446.67it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1199.34it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1474.40it/s]\n",
      "100%|██████████| 142/142 [00:00<00:00, 1156.44it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1209.73it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1722.56it/s]\n",
      "100%|██████████| 122/122 [00:00<00:00, 1490.60it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1321.96it/s]\n",
      "100%|██████████| 127/127 [00:00<00:00, 1590.44it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 1606.28it/s]\n",
      "100%|██████████| 130/130 [00:00<00:00, 1473.14it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1551.83it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 1266.91it/s]\n"
     ]
    }
   ],
   "source": [
    "root_path = '/workdir/radish/PET-CT/3D_reggan/train/'\n",
    "save_dir = '3d_model_data_5/train'\n",
    "index, num =  save(save_dir, root_path, max_records = 10000)\n",
    "print(f'Number of patients: {num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [00:00<00:00, 1105.82it/s]\n",
      "100%|██████████| 162/162 [00:00<00:00, 228.88it/s]\n",
      "100%|██████████| 155/155 [00:00<00:00, 1407.92it/s]\n",
      " 16%|█▋        | 27/166 [00:00<00:00, 1210.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "root_path = '/workdir/radish/PET-CT/3D_reggan/val/'\n",
    "save_dir = '3d_model_data_5/val'\n",
    "index, num =  save(save_dir, root_path, max_records = 500)\n",
    "print(f'Number of patients: {num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load ('/home/huutien/3D_PET-CT/3d_model_data_5/train/A/0.npy')\n",
    "# b = np.load ('/home/huutien/3D_PET-CT/3d_model_data/train/B/0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 256, 256)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated OVERLAP: 0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "CHUNK_DEPTH = 7\n",
    "D, H, W = 300, 256, 256  # Assuming voxel shape is (D, 256, 256)\n",
    "\n",
    "# Calculate the required number of chunks\n",
    "num_chunks = math.ceil(D / CHUNK_DEPTH)\n",
    "\n",
    "# Calculate overlap to ensure we fully cover D with equal-sized chunks (CHUNK_DEPTH)\n",
    "if num_chunks > 1:\n",
    "    OVERLAP = int((num_chunks * CHUNK_DEPTH - D) / (num_chunks - 1))\n",
    "else:\n",
    "    OVERLAP = 0  # No overlap needed if only one chunk is required\n",
    "\n",
    "print(f\"Calculated OVERLAP: {OVERLAP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERLAP = CHUNK_DEPTH -  (math.ceil(D / CHUNK_DEPTH) * CHUNK_DEPTH - D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OVERLAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from ./logs/Experiment_ResidualUNet3D_lr1e-4/checkpoints/model_epoch_29.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2151/2582932746.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(CHECKPOINT_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from epoch 29\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "experiment_name = \"Experiment_ResidualUNet3D_lr1e-4\"\n",
    "N_EPOCHS = 100\n",
    "LOG_DIR = f'./logs/{experiment_name}'\n",
    "CHECKPOINT_DIR = LOG_DIR + '/checkpoints'\n",
    "CHECKPOINT_PATH = CHECKPOINT_DIR + '/model_epoch_29.pth'  # Update to the latest checkpoint if needed\n",
    "\n",
    "from model.unet3d import ResidualUNet3D, ResidualUNetSE3D\n",
    "\n",
    "# Initialize model\n",
    "IN_CHANNELS, OUT_CHANNELS = 1, 1\n",
    "model = ResidualUNetSE3D(IN_CHANNELS, OUT_CHANNELS).to('cuda:1')\n",
    "# read 3D data \n",
    "import numpy as np\n",
    "\n",
    "file_path = '/workdir/radish/PET-CT/3D_reggan/dunganh/1.2.840.113619.2.55.3.663376.78.1704246084.428/predicted_volume.npy'\n",
    "\n",
    "# Load checkpoint if available\n",
    "if os.path.isfile(CHECKPOINT_PATH):\n",
    "    print(f\"Loading checkpoint from {CHECKPOINT_PATH}\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']  # Resume from the saved epoch\n",
    "    print(f\"Resuming from epoch {start_epoch}\")\n",
    "\n",
    "model = model.to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel = np.load(file_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk starting at index 0...\n",
      "Processing chunk starting at index 4...\n",
      "Processing chunk starting at index 8...\n",
      "Processing chunk starting at index 12...\n",
      "Processing chunk starting at index 16...\n",
      "Processing chunk starting at index 20...\n",
      "Processing chunk starting at index 24...\n",
      "Processing chunk starting at index 28...\n",
      "Processing chunk starting at index 32...\n",
      "Processing chunk starting at index 36...\n",
      "Processing chunk starting at index 40...\n",
      "Processing chunk starting at index 44...\n",
      "Processing chunk starting at index 48...\n",
      "Processing chunk starting at index 52...\n",
      "Processing chunk starting at index 56...\n",
      "Processing chunk starting at index 60...\n",
      "Processing chunk starting at index 64...\n",
      "Processing chunk starting at index 68...\n",
      "Processing chunk starting at index 72...\n",
      "Processing chunk starting at index 76...\n",
      "Processing chunk starting at index 80...\n",
      "Processing chunk starting at index 84...\n",
      "Processing chunk starting at index 88...\n",
      "Processing chunk starting at index 92...\n",
      "Processing chunk starting at index 96...\n",
      "Processing chunk starting at index 100...\n",
      "Processing chunk starting at index 104...\n",
      "Processing chunk starting at index 108...\n",
      "Processing chunk starting at index 112...\n",
      "Processing chunk starting at index 116...\n",
      "Processing chunk starting at index 120...\n",
      "Processing chunk starting at index 124...\n",
      "Processing chunk starting at index 128...\n",
      "Processing chunk starting at index 132...\n",
      "Processing chunk starting at index 136...\n",
      "Processing chunk starting at index 140...\n",
      "Processing chunk starting at index 144...\n",
      "Processing chunk starting at index 148...\n",
      "Processing chunk starting at index 152...\n",
      "Processing chunk starting at index 156...\n",
      "Processing chunk starting at index 160...\n",
      "Processing chunk starting at index 164...\n",
      "Processing chunk starting at index 168...\n",
      "Processing chunk starting at index 172...\n",
      "Processing chunk starting at index 176...\n",
      "Processing chunk starting at index 180...\n",
      "Processing chunk starting at index 184...\n",
      "Processing chunk starting at index 188...\n",
      "Processing chunk starting at index 192...\n",
      "Processing chunk starting at index 196...\n",
      "Processing chunk starting at index 200...\n",
      "Processing chunk starting at index 204...\n",
      "Processing chunk starting at index 208...\n",
      "Processing chunk starting at index 212...\n",
      "Processing chunk starting at index 216...\n",
      "Processing chunk starting at index 220...\n",
      "Processing chunk starting at index 224...\n",
      "Processing chunk starting at index 228...\n",
      "Processing chunk starting at index 232...\n",
      "Processing chunk starting at index 236...\n",
      "Processing chunk starting at index 240...\n",
      "Processing chunk starting at index 244...\n",
      "Processing chunk starting at index 248...\n",
      "Processing chunk starting at index 252...\n",
      "Processing chunk starting at index 256...\n",
      "Processing chunk starting at index 260...\n",
      "Processing chunk starting at index 264...\n",
      "Processing chunk starting at index 268...\n",
      "Processing chunk starting at index 272...\n",
      "Processing chunk starting at index 276...\n",
      "Processing chunk starting at index 280...\n",
      "Processing chunk starting at index 284...\n",
      "Processing chunk starting at index 288...\n",
      "Processing chunk starting at index 292...\n",
      "Processing chunk starting at index 296...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Define the depth of each chunk and overlap\n",
    "CHUNK_DEPTH = 7\n",
    "OVERLAP = 3  # Overlapping depth for each chunk\n",
    "D, H, W = voxel.shape  # Assuming voxel shape is (D, 256, 256)\n",
    "\n",
    "# Ensure voxel is on GPU\n",
    "voxel = torch.tensor(voxel, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to('cuda:1')  # Shape: (1, 1, D, 256, 256)\n",
    "voxel = voxel / 32767.0 \n",
    "voxel =  (voxel - 0.5 ) * 2 \n",
    "\n",
    "# Prepare tensors to store accumulated output and weights\n",
    "output_accum = torch.zeros((1, 1, D, H, W), dtype=torch.float32).to('cuda:1')  # Accumulated output\n",
    "weight_accum = torch.zeros((1, 1, D, H, W), dtype=torch.float32).to('cuda:1')  # Weight mask\n",
    "\n",
    "# Process the voxel in chunks along the depth dimension\n",
    "start_idx = 0\n",
    "while start_idx < D:\n",
    "    print(f\"Processing chunk starting at index {start_idx}...\")\n",
    "    # Calculate end index for the chunk, with overlap\n",
    "    end_idx = min(start_idx + CHUNK_DEPTH, D)\n",
    "    \n",
    "    # If this is the last chunk and smaller than CHUNK_DEPTH, adjust start_idx for overlap\n",
    "    tmp = start_idx\n",
    "    if end_idx - start_idx < CHUNK_DEPTH and start_idx != 0:\n",
    "        start_idx = max(0, end_idx - CHUNK_DEPTH)  # Adjust start_idx to include overlap with the previous chunk\n",
    "    \n",
    "    # Select the chunk from the voxel\n",
    "    chunk = voxel[:, :, start_idx:end_idx, :, :]  # Shape: (1, 1, CHUNK_DEPTH, 256, 256) or smaller if at the last chunk\n",
    "\n",
    "    # Pass the chunk through the model\n",
    "    with torch.no_grad():\n",
    "        output_chunk = model(chunk)\n",
    "\n",
    "    # Determine the slice in the full output corresponding to this chunk\n",
    "    output_start = start_idx\n",
    "    output_end = min(start_idx + CHUNK_DEPTH, D)\n",
    "    \n",
    "    # Add the model's output to the accumulated tensor\n",
    "    output_accum[:, :, output_start:output_end, :, :] += output_chunk[:, :, :output_end - output_start, :, :]\n",
    "    weight_accum[:, :, output_start:output_end, :, :] += 1  # Increment weights for overlapping regions\n",
    "\n",
    "    # Move to the next chunk position, taking the overlap into account\n",
    "    # print(start_idx, CHUNK_DEPTH, OVERLAP)\n",
    "    start_idx = tmp\n",
    "    start_idx = start_idx + CHUNK_DEPTH - OVERLAP\n",
    "    # print(start_idx)\n",
    "\n",
    "# Normalize the accumulated output by the weight mask to compute the average for overlapping regions\n",
    "output_voxel = output_accum / weight_accum\n",
    "# output_voxel = output_voxel.squeeze().cpu().numpy()  # Convert back to numpy if needed\n",
    "output_voxel = output_voxel.mul(0.5).add(0.5).clamp(0, 1)\n",
    "output_voxel = output_voxel * 32767.0\n",
    "output_voxel = output_voxel.squeeze().cpu().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 29276.516, (299, 256, 256))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_voxel.min(), output_voxel.max(), output_voxel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 256, 256) torch.Size([1, 1, 299, 256, 256]) 0.0 29276.516\n"
     ]
    }
   ],
   "source": [
    "# output_voxel = output_voxel.mul(0.5).add(0.5).clamp(0, 1)\n",
    "# output_voxel = output_voxel * 32767.0\n",
    "# output_voxel = output_voxel.squeeze().cpu().numpy() \n",
    "\n",
    "print(output_voxel.shape, voxel.shape, output_voxel.min(), output_voxel.max())\n",
    "# Save the output voxel\n",
    "np.save('/workdir/radish/PET-CT/3D_reggan/dunganh/1.2.840.113619.2.55.3.663376.78.1704246084.428/3D_model_overlap.npy', output_voxel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2.,\n",
       "        2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1.,\n",
       "        2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2.,\n",
       "        2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1.,\n",
       "        2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2.,\n",
       "        2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1.,\n",
       "        2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2.,\n",
       "        2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1.,\n",
       "        2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2.,\n",
       "        2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1.,\n",
       "        2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2.,\n",
       "        2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1.,\n",
       "        2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2.,\n",
       "        2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1.,\n",
       "        2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 3., 3.,\n",
       "        3., 2., 2., 2., 2.], device='cuda:1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arg max of weight_accum[0,0, :, 0, 0 ]\n",
    "tmp = weight_accum[0,0, :, 0, 0 ]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 7, 256, 256]) 1\n",
      "torch.Size([1, 1, 3, 256, 256]) 2\n",
      "torch.Size([1, 1, 6, 256, 256]) 3\n",
      "torch.Size([1, 1, 2, 256, 256]) 4\n",
      "torch.Size([1, 1, 5, 256, 256]) 5\n",
      "torch.Size([1, 1, 1, 256, 256]) 6\n",
      "torch.Size([1, 1, 4, 256, 256]) 7\n",
      "torch.Size([1, 1, 7, 256, 256]) 8\n",
      "torch.Size([1, 1, 3, 256, 256]) 9\n",
      "torch.Size([1, 1, 6, 256, 256]) 10\n",
      "torch.Size([1, 1, 2, 256, 256]) 11\n",
      "torch.Size([1, 1, 5, 256, 256]) 12\n",
      "torch.Size([1, 1, 1, 256, 256]) 13\n",
      "torch.Size([1, 1, 4, 256, 256]) 14\n",
      "torch.Size([1, 1, 7, 256, 256]) 15\n",
      "torch.Size([1, 1, 3, 256, 256]) 16\n",
      "torch.Size([1, 1, 6, 256, 256]) 17\n",
      "torch.Size([1, 1, 2, 256, 256]) 18\n",
      "torch.Size([1, 1, 5, 256, 256]) 19\n",
      "torch.Size([1, 1, 1, 256, 256]) 20\n",
      "torch.Size([1, 1, 4, 256, 256]) 21\n",
      "torch.Size([1, 1, 7, 256, 256]) 22\n",
      "torch.Size([1, 1, 3, 256, 256]) 23\n",
      "torch.Size([1, 1, 6, 256, 256]) 24\n",
      "torch.Size([1, 1, 2, 256, 256]) 25\n",
      "torch.Size([1, 1, 5, 256, 256]) 26\n",
      "torch.Size([1, 1, 1, 256, 256]) 27\n",
      "torch.Size([1, 1, 4, 256, 256]) 28\n",
      "torch.Size([1, 1, 7, 256, 256]) 29\n",
      "torch.Size([1, 1, 3, 256, 256]) 30\n",
      "torch.Size([1, 1, 6, 256, 256]) 31\n",
      "torch.Size([1, 1, 2, 256, 256]) 32\n",
      "torch.Size([1, 1, 5, 256, 256]) 33\n",
      "torch.Size([1, 1, 1, 256, 256]) 34\n",
      "torch.Size([1, 1, 4, 256, 256]) 35\n",
      "torch.Size([1, 1, 7, 256, 256]) 36\n",
      "torch.Size([1, 1, 3, 256, 256]) 37\n",
      "torch.Size([1, 1, 6, 256, 256]) 38\n",
      "torch.Size([1, 1, 2, 256, 256]) 39\n",
      "torch.Size([1, 1, 5, 256, 256]) 40\n",
      "torch.Size([1, 1, 1, 256, 256]) 41\n",
      "torch.Size([1, 1, 4, 256, 256]) 42\n",
      "torch.Size([1, 1, 7, 256, 256]) 43\n",
      "torch.Size([1, 1, 3, 256, 256]) 44\n",
      "torch.Size([1, 1, 6, 256, 256]) 45\n",
      "torch.Size([1, 1, 2, 256, 256]) 46\n",
      "torch.Size([1, 1, 5, 256, 256]) 47\n",
      "torch.Size([1, 1, 1, 256, 256]) 48\n",
      "torch.Size([1, 1, 4, 256, 256]) 49\n",
      "torch.Size([1, 1, 7, 256, 256]) 50\n",
      "torch.Size([1, 1, 3, 256, 256]) 51\n",
      "torch.Size([1, 1, 6, 256, 256]) 52\n",
      "torch.Size([1, 1, 2, 256, 256]) 53\n",
      "torch.Size([1, 1, 5, 256, 256]) 54\n",
      "torch.Size([1, 1, 1, 256, 256]) 55\n",
      "torch.Size([1, 1, 4, 256, 256]) 56\n",
      "torch.Size([1, 1, 7, 256, 256]) 57\n",
      "torch.Size([1, 1, 3, 256, 256]) 58\n",
      "torch.Size([1, 1, 6, 256, 256]) 59\n",
      "torch.Size([1, 1, 2, 256, 256]) 60\n",
      "torch.Size([1, 1, 5, 256, 256]) 61\n",
      "torch.Size([1, 1, 1, 256, 256]) 62\n",
      "torch.Size([1, 1, 4, 256, 256]) 63\n",
      "torch.Size([1, 1, 7, 256, 256]) 64\n",
      "torch.Size([1, 1, 3, 256, 256]) 65\n",
      "torch.Size([1, 1, 6, 256, 256]) 66\n",
      "torch.Size([1, 1, 2, 256, 256]) 67\n",
      "torch.Size([1, 1, 5, 256, 256]) 68\n",
      "torch.Size([1, 1, 5, 256, 256]) 69\n"
     ]
    }
   ],
   "source": [
    "i = 1 \n",
    "for vox in output_chunks: \n",
    "    print(vox.shape, i )\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification dataset saved to classification_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate features\n",
    "age = np.random.randint(18, 66, size=n_samples)  # Age 18-65\n",
    "income = np.random.randint(1000, 10001, size=n_samples)  # Income 1000-10000 USD\n",
    "gender = np.random.choice([0, 1], size=n_samples)  # Gender: 0 = Male, 1 = Female\n",
    "browsing_time = np.random.uniform(1, 120, size=n_samples)  # Browsing time in minutes\n",
    "product_rating = np.random.uniform(1, 5, size=n_samples)  # Product rating 1-5\n",
    "\n",
    "# Generate target variable (Buy_Product) with some randomness\n",
    "# Customers with high income, high browsing time, and high product ratings are more likely to buy\n",
    "buy_probability = (\n",
    "    0.3 * (income / 10000) +\n",
    "    0.2 * (browsing_time / 120) +\n",
    "    0.3 * (product_rating / 5) +\n",
    "    0.2 * (gender) +\n",
    "    np.random.normal(0, 0.1, n_samples)\n",
    ")\n",
    "\n",
    "# Convert probabilities to binary classification (threshold = 0.5)\n",
    "buy_product = (buy_probability > 0.5).astype(int)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Age': age,\n",
    "    'Income': income,\n",
    "    'Gender': gender,\n",
    "    'Browsing_Time': browsing_time,\n",
    "    'Product_Rating': product_rating,\n",
    "    'Buy_Product': buy_product\n",
    "})\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "output_file = 'classification_data.csv'\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Classification dataset saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BBDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
